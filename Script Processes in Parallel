#!/bin/bash 
#this script is to use wget to Parallel downloading from the txts.

#define directory
scripts_dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
base_dir="$(dirname "$scripts_dir")"
raw_data_dir="$scripts_dir/image"

#define all the txts that include the downloading urls like 1.txt 2.txt 3.txt 4.txt 5.txt 
declare -a class_names=(
"1"
"2"
"3"
"4"
"5"
	)
			
Njob=${#class_names[@]} #任务总数	

echo "任务总数为$Njob"

Nproc=2 #最大并发进程数, 

echo "最大并发进程数$Nproc"

function PushQue {      #将PID值追加到队列中 

           Que="$Que $1" 

           Nrun=$(($Nrun+1)) 

}

function GenQue {       #更新队列信息，先清空队列信息，然后检索生成新的队列信息 

           OldQue=$Que 

           Que=""; Nrun=0 

           for PID in $OldQue; do 

                 if [[ -d /proc/$PID ]]; then 

                        PushQue $PID 

                 fi 

           done 

}

function ChkQue {       #检查队列信息，如果有已经结束了的进程的PID，那么更新队列信息 

           OldQue=$Que 

           for PID in $OldQue; do 

                 if [[ ! -d /proc/$PID ]];   then 

                 GenQue; break 

                 fi 

           done 

} 

 

for ((i=0; i<$Njob; i++)); do 


#your code begins here.
	urls_file="$scripts_dir/${class_names[i]}.txt"
	images_dir="$raw_data_dir/${class_names[i]}"
	mkdir -p "$images_dir"
	echo "${class_names[i]}.txt Total: $(cat $urls_file | wc -l)"
	echo "Downloading ..."
	date
	wget -nc -q --timeout=5 --tries=2 -i "$urls_file" -P "$images_dir" &
#your code ends here. Don't forget & at last row.

           PID=$! 

           PushQue $PID 

           while [[ $Nrun -ge $Nproc ]]; do          # 如果Nrun大于Nproc，就一直ChkQue 

                 ChkQue 

                 sleep 3 

           done 

done
